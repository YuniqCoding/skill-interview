'use client';

import { useState, useEffect, useRef, useCallback } from 'react';
import { useRouter } from 'next/navigation';
import { motion, AnimatePresence } from 'framer-motion';
import { Button, Card } from '@/components/ui';
import { WaveAnimation } from '@/components/WaveAnimation';
import { RecordButton } from '@/components/RecordButton';
import { useInterviewStore } from '@/stores/interviewStore';
import { JOB_POSITION_LABELS } from '@/types';

type InterviewPhase = 
  | 'loading'      // ë©´ì ‘ ì‹œì‘ ì¤‘
  | 'ai-speaking'  // AIê°€ ì§ˆë¬¸ ì½ëŠ” ì¤‘
  | 'user-ready'   // ì‚¬ìš©ì ë‹µë³€ ëŒ€ê¸°
  | 'user-recording' // ì‚¬ìš©ì ë…¹ìŒ ì¤‘
  | 'processing'   // ë‹µë³€ ì²˜ë¦¬ ì¤‘
  | 'completed';   // ë©´ì ‘ ì™„ë£Œ

const TOTAL_QUESTIONS = 5;

export default function InterviewPage() {
  const router = useRouter();
  const { 
    userInfo, 
    candidateId,
    qaHistory,
    interviewStartTime,
    setStatus, 
    addQAItem, 
    setInterviewStartTime,
    setInterviewEndTime,
    setResult,
  } = useInterviewStore();

  // ìƒíƒœ
  const [phase, setPhase] = useState<InterviewPhase>('loading');
  const [threadId, setThreadId] = useState<string | null>(null);
  const [currentQuestion, setCurrentQuestion] = useState('');
  const [questionNumber, setQuestionNumber] = useState(1);
  const [recordingTime, setRecordingTime] = useState(0);
  const [audioLevel, setAudioLevel] = useState(0);
  const [error, setError] = useState<string | null>(null);
  const [isSaving, setIsSaving] = useState(false);
  const [saveSuccess, setSaveSuccess] = useState(false);

  // Refs
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const isInitializedRef = useRef<boolean>(false);

  // ì˜¤ë””ì˜¤ ë ˆë²¨ ë¶„ì„
  const analyzeAudio = useCallback(() => {
    if (!analyserRef.current) return;
    
    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
    analyserRef.current.getByteFrequencyData(dataArray);
    const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
    setAudioLevel(Math.min(average / 128, 1));
    
    animationFrameRef.current = requestAnimationFrame(analyzeAudio);
  }, []);

  // Assistantë¡œ ë©´ì ‘ ì‹œì‘
  const startInterview = async () => {
    if (!userInfo) return;

    try {
      setPhase('loading');
      setError(null);

      const response = await fetch('/api/assistant/start', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          jobPosition: userInfo.jobPosition,
        }),
      });

      const result = await response.json();

      if (result.success && result.data) {
        setThreadId(result.data.threadId);
        setCurrentQuestion(result.data.question);
        setQuestionNumber(result.data.questionNumber);
        setInterviewStartTime(new Date());
        
        // ì²« ì§ˆë¬¸ ì½ê¸°
        await speakQuestion(result.data.question);
      } else {
        throw new Error(result.error || 'ë©´ì ‘ ì‹œì‘ ì‹¤íŒ¨');
      }
    } catch (err) {
      console.error('Start interview error:', err);
      setError('ë©´ì ‘ì„ ì‹œì‘í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      setPhase('loading');
    }
  };

  // TTSë¡œ ì§ˆë¬¸ ì½ê¸°
  const speakQuestion = async (question: string) => {
    try {
      setPhase('ai-speaking');

      const response = await fetch('/api/text-to-speech', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text: question }),
      });

      const result = await response.json();

      if (result.success && result.data.audio) {
        const audioBlob = base64ToBlob(result.data.audio, 'audio/mp3');
        const audioUrl = URL.createObjectURL(audioBlob);

        const audio = new Audio(audioUrl);
        audioRef.current = audio;

        audio.onended = () => {
          setPhase('user-ready');
          URL.revokeObjectURL(audioUrl);
        };

        audio.onerror = () => {
          console.error('Audio playback error');
          setPhase('user-ready');
        };

        await audio.play();
      } else {
        setPhase('user-ready');
      }
    } catch (err) {
      console.error('TTS error:', err);
      setPhase('user-ready');
    }
  };

  // Base64ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
  const base64ToBlob = (base64: string, mimeType: string): Blob => {
    const byteCharacters = atob(base64);
    const byteNumbers = new Array(byteCharacters.length);
    for (let i = 0; i < byteCharacters.length; i++) {
      byteNumbers[i] = byteCharacters.charCodeAt(i);
    }
    const byteArray = new Uint8Array(byteNumbers);
    return new Blob([byteArray], { type: mimeType });
  };

  // ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      const audioContext = new AudioContext();
      audioContextRef.current = audioContext;
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      analyserRef.current = analyser;

      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        await processAnswer(audioBlob);
      };

      mediaRecorder.start();
      setPhase('user-recording');
      setRecordingTime(0);

      recordingIntervalRef.current = setInterval(() => {
        setRecordingTime((prev) => prev + 1);
      }, 1000);

      analyzeAudio();
    } catch (err) {
      console.error('Recording start error:', err);
      setError('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }

    if (recordingIntervalRef.current) {
      clearInterval(recordingIntervalRef.current);
    }

    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
    }

    if (audioContextRef.current) {
      audioContextRef.current.close();
    }

    setPhase('processing');
  };

  // ë‹µë³€ ì²˜ë¦¬ (STT â†’ Assistant)
  const processAnswer = async (audioBlob: Blob) => {
    try {
      // 1. STTë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');

      const sttResponse = await fetch('/api/speech-to-text', {
        method: 'POST',
        body: formData,
      });

      const sttResult = await sttResponse.json();
      let answerText = '(ìŒì„± ì¸ì‹ ì‹¤íŒ¨)';

      if (sttResult.success && sttResult.data.text) {
        answerText = sttResult.data.text;
      }

      // QA ê¸°ë¡ ì €ì¥
      addQAItem({
        question: currentQuestion,
        answer: answerText,
      });

      // 2. Assistantì—ê²Œ ë‹µë³€ ì „ì†¡
      if (!threadId) {
        throw new Error('Thread IDê°€ ì—†ìŠµë‹ˆë‹¤.');
      }

      const assistantResponse = await fetch('/api/assistant/respond', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          threadId,
          answer: answerText,
          questionNumber,
        }),
      });

      const assistantResult = await assistantResponse.json();

      if (assistantResult.success && assistantResult.data) {
        if (assistantResult.data.isCompleted) {
          // ë©´ì ‘ ì™„ë£Œ
          setInterviewEndTime(new Date());
          setPhase('completed');
        } else {
          // ë‹¤ìŒ ì§ˆë¬¸
          setCurrentQuestion(assistantResult.data.response);
          setQuestionNumber(assistantResult.data.questionNumber);
          await speakQuestion(assistantResult.data.response);
        }
      } else {
        throw new Error(assistantResult.error || 'Assistant ì‘ë‹µ ì‹¤íŒ¨');
      }
    } catch (err) {
      console.error('Process answer error:', err);
      
      // ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ë‹¤ìŒìœ¼ë¡œ ì§„í–‰
      if (questionNumber >= TOTAL_QUESTIONS) {
        setInterviewEndTime(new Date());
        setPhase('completed');
      } else {
        setError('ë‹µë³€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
        setPhase('user-ready');
      }
    }
  };

  // ë©´ì ‘ ë°ì´í„° ì €ì¥ ë° ì¢…ë£Œ
  const saveAndFinish = async () => {
    if (!userInfo) return;

    setIsSaving(true);
    setError(null);

    try {
      // ë©´ì ‘ ì†Œìš” ì‹œê°„ ê³„ì‚° (ì´ˆ)
      const duration = interviewStartTime
        ? Math.floor((new Date().getTime() - new Date(interviewStartTime).getTime()) / 1000)
        : 0;

      // ì›¹í›…ìœ¼ë¡œ ë©´ì ‘ ë°ì´í„° ì „ì†¡
      const response = await fetch('/api/save-interview', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          candidateId: candidateId || `temp-${Date.now()}`,
          jobPosition: userInfo.jobPosition,
          phone: userInfo.phone,
          email: userInfo.email,
          questions: qaHistory.map((qa) => qa.question),
          answers: qaHistory.map((qa) => qa.answer),
          duration,
        }),
      });

      const result = await response.json();

      if (result.success) {
        setSaveSuccess(true);
        console.log('Interview saved:', result.data);

        // ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìŠ¤í† ì–´ì— ì €ì¥
        if (result.data?.analysis) {
          setResult(result.data.analysis);
          console.log('Analysis result saved:', result.data.analysis);
        }
      } else {
        throw new Error(result.error || 'ì €ì¥ ì‹¤íŒ¨');
      }
    } catch (err) {
      console.error('Save interview error:', err);
      setError('ë©´ì ‘ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsSaving(false);
    }
  };

  // ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™
  const goToResult = () => {
    setStatus('analyzing');
    router.push('/result');
  };

  // ğŸ§ª í…ŒìŠ¤íŠ¸ìš©: ì‹¤ì œ Make ì›¹í›… í˜¸ì¶œ
  const testWithMakeWebhook = async () => {
    setIsSaving(true);
    setError(null);

    try {
      const testData = {
        candidateId: candidateId || 'test-candidate-123',
        jobPosition: userInfo?.jobPosition || 'frontend',
        phone: userInfo?.phone || '010-1234-5678',
        email: userInfo?.email || 'test@example.com',
        questions: qaHistory.length > 0 
          ? qaHistory.map((qa) => qa.question)
          : ['ìê¸°ì†Œê°œ', 'ë„ì „ì  í”„ë¡œì íŠ¸', 'í˜‘ì—… ë„êµ¬'],
        answers: qaHistory.length > 0 
          ? qaHistory.map((qa) => qa.answer)
          : ['í…ŒìŠ¤íŠ¸ ë‹µë³€ 1', 'í…ŒìŠ¤íŠ¸ ë‹µë³€ 2', 'í…ŒìŠ¤íŠ¸ ë‹µë³€ 3'],
        duration: interviewStartTime
          ? Math.floor((new Date().getTime() - new Date(interviewStartTime).getTime()) / 1000)
          : 300,
      };

      console.log('ğŸ§ª Sending to Make webhook:', testData);

      // ì‹¤ì œ Make ì›¹í›… í˜¸ì¶œ (mock=false ë˜ëŠ” íŒŒë¼ë¯¸í„° ì—†ìŒ)
      const response = await fetch('/api/save-interview', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(testData),
      });

      const result = await response.json();
      console.log('ğŸ§ª Make API Response:', result);

      if (result.success) {
        setSaveSuccess(true);
        if (result.data?.analysis) {
          setResult(result.data.analysis);
          console.log('ğŸ§ª Analysis saved to store:', result.data.analysis);
        }
      } else {
        throw new Error(result.error || 'Make í˜¸ì¶œ ì‹¤íŒ¨');
      }
    } catch (err) {
      console.error('ğŸ§ª Make test error:', err);
      setError(err instanceof Error ? err.message : 'Make í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsSaving(false);
    }
  };

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ
  useEffect(() => {
    if (!userInfo) {
      router.push('/');
      return;
    }

    if (isInitializedRef.current) {
      return;
    }
    isInitializedRef.current = true;

    startInterview();

    return () => {
      if (audioRef.current) {
        audioRef.current.pause();
      }
      if (recordingIntervalRef.current) {
        clearInterval(recordingIntervalRef.current);
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  if (!userInfo) {
    return null;
  }

  return (
    <div className="min-h-screen bg-slate-950 p-4">
      <div className="max-w-2xl mx-auto">
        {/* í—¤ë” */}
        <motion.div
          initial={{ opacity: 0, y: -20 }}
          animate={{ opacity: 1, y: 0 }}
          className="mb-8"
        >
          <div className="flex items-center justify-between mb-4">
            <span className="text-slate-400 text-sm">
              {JOB_POSITION_LABELS[userInfo.jobPosition]} ë©´ì ‘
            </span>
            <div className="flex items-center gap-2">
              {/* ğŸ§ª í…ŒìŠ¤íŠ¸ìš©: ë°”ë¡œ ì™„ë£Œ í™”ë©´ìœ¼ë¡œ */}
              {phase !== 'completed' && (
                <button
                  onClick={() => setPhase('completed')}
                  className="text-xs px-2 py-1 bg-amber-500/20 text-amber-400 rounded hover:bg-amber-500/30"
                >
                  ğŸ§ª Skip
                </button>
              )}
              <span className="text-indigo-400 font-medium">
                {questionNumber} / {TOTAL_QUESTIONS}
              </span>
            </div>
          </div>
          <div className="h-2 bg-slate-800 rounded-full overflow-hidden">
            <motion.div
              className="h-full bg-gradient-to-r from-indigo-500 to-emerald-500"
              initial={{ width: 0 }}
              animate={{
                width: `${((phase === 'completed' ? questionNumber : questionNumber - 1) / TOTAL_QUESTIONS) * 100}%`,
              }}
              transition={{ duration: 0.5 }}
            />
          </div>
        </motion.div>

        {/* ë©”ì¸ ì¹´ë“œ */}
        <Card variant="default" padding="lg">
          <AnimatePresence mode="wait">
            {/* ë¡œë”© ìƒíƒœ */}
            {phase === 'loading' && (
              <motion.div
                key="loading"
                initial={{ opacity: 0 }}
                animate={{ opacity: 1 }}
                exit={{ opacity: 0 }}
                className="py-16 text-center"
              >
                <motion.div
                  animate={{ rotate: 360 }}
                  transition={{ duration: 1, repeat: Infinity, ease: 'linear' }}
                  className="w-16 h-16 border-4 border-indigo-500 border-t-transparent rounded-full mx-auto mb-6"
                />
                <p className="text-slate-400">AI ë©´ì ‘ê´€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...</p>
                {error && (
                  <div className="mt-4">
                    <p className="text-red-400 mb-4">{error}</p>
                    <Button variant="primary" onClick={startInterview}>
                      ë‹¤ì‹œ ì‹œë„
                    </Button>
                  </div>
                )}
              </motion.div>
            )}

            {/* AI ì§ˆë¬¸ ì¤‘ */}
            {phase === 'ai-speaking' && (
              <motion.div
                key="ai-speaking"
                initial={{ opacity: 0 }}
                animate={{ opacity: 1 }}
                exit={{ opacity: 0 }}
                className="py-8"
              >
                <div className="flex justify-center mb-8">
                  <motion.div
                    className="w-24 h-24 rounded-full bg-indigo-500/20 border-2 border-indigo-500/50 flex items-center justify-center"
                    animate={{ scale: [1, 1.05, 1] }}
                    transition={{ duration: 1.5, repeat: Infinity }}
                  >
                    <span className="text-4xl">ğŸ¤–</span>
                  </motion.div>
                </div>

                <div className="flex justify-center mb-6">
                  <WaveAnimation isActive={true} variant="speaking" className="h-8" />
                </div>

                <div className="text-center">
                  <p className="text-slate-500 text-sm mb-2">ì§ˆë¬¸ {questionNumber}</p>
                  <p className="text-white text-lg leading-relaxed">{currentQuestion}</p>
                </div>
              </motion.div>
            )}

            {/* ì‚¬ìš©ì ë‹µë³€ ëŒ€ê¸° / ë…¹ìŒ ì¤‘ */}
            {(phase === 'user-ready' || phase === 'user-recording') && (
              <motion.div
                key="user-turn"
                initial={{ opacity: 0 }}
                animate={{ opacity: 1 }}
                exit={{ opacity: 0 }}
                className="py-8"
              >
                <div className="mb-8 p-4 bg-slate-800/50 rounded-xl">
                  <p className="text-slate-500 text-sm mb-2">ì§ˆë¬¸ {questionNumber}</p>
                  <p className="text-white leading-relaxed">{currentQuestion}</p>
                </div>

                {phase === 'user-recording' && (
                  <div className="flex justify-center mb-6">
                    <WaveAnimation
                      isActive={true}
                      audioLevel={audioLevel}
                      variant="listening"
                      className="h-12"
                    />
                  </div>
                )}

                <div className="flex justify-center">
                  <RecordButton
                    isRecording={phase === 'user-recording'}
                    isDisabled={false}
                    onStart={startRecording}
                    onStop={stopRecording}
                    recordingTime={recordingTime}
                  />
                </div>

                {error && (
                  <p className="text-red-400 text-center mt-4 text-sm">{error}</p>
                )}
              </motion.div>
            )}

            {/* ë‹µë³€ ì²˜ë¦¬ ì¤‘ */}
            {phase === 'processing' && (
              <motion.div
                key="processing"
                initial={{ opacity: 0 }}
                animate={{ opacity: 1 }}
                exit={{ opacity: 0 }}
                className="py-16 text-center"
              >
                <motion.div
                  animate={{ rotate: 360 }}
                  transition={{ duration: 1, repeat: Infinity, ease: 'linear' }}
                  className="w-12 h-12 border-4 border-emerald-500 border-t-transparent rounded-full mx-auto mb-4"
                />
                <p className="text-slate-400">ë‹µë³€ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...</p>
              </motion.div>
            )}

            {/* ë©´ì ‘ ì™„ë£Œ */}
            {phase === 'completed' && (
              <motion.div
                key="completed"
                initial={{ opacity: 0, scale: 0.9 }}
                animate={{ opacity: 1, scale: 1 }}
                exit={{ opacity: 0 }}
                className="py-12 text-center"
              >
                <motion.div
                  initial={{ scale: 0 }}
                  animate={{ scale: 1 }}
                  transition={{ type: 'spring', stiffness: 200 }}
                  className="w-20 h-20 rounded-full bg-emerald-500/20 flex items-center justify-center mx-auto mb-6"
                >
                  <svg className="w-10 h-10 text-emerald-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 13l4 4L19 7" />
                  </svg>
                </motion.div>

                <h2 className="text-2xl font-bold text-white mb-2">ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!</h2>
                <p className="text-slate-400 mb-6">
                  ì´ {TOTAL_QUESTIONS}ê°œì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì…¨ìŠµë‹ˆë‹¤.
                </p>

                {/* ì €ì¥ ì„±ê³µ ë©”ì‹œì§€ */}
                {saveSuccess && (
                  <motion.div
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    className="mb-6 p-4 bg-emerald-500/20 border border-emerald-500/30 rounded-lg"
                  >
                    <p className="text-emerald-400">
                      âœ… ë©´ì ‘ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!
                    </p>
                  </motion.div>
                )}

                {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
                {error && (
                  <motion.div
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    className="mb-6 p-4 bg-red-500/20 border border-red-500/30 rounded-lg"
                  >
                    <p className="text-red-400">{error}</p>
                  </motion.div>
                )}

                <div className="flex flex-col gap-3">
                  {!saveSuccess ? (
                    <>
                      <Button
                        variant="primary"
                        size="lg"
                        onClick={saveAndFinish}
                        disabled={isSaving}
                        leftIcon={
                          isSaving ? (
                            <motion.div
                              animate={{ rotate: 360 }}
                              transition={{ duration: 1, repeat: Infinity, ease: 'linear' }}
                              className="w-5 h-5 border-2 border-white border-t-transparent rounded-full"
                            />
                          ) : (
                            <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 13l4 4L19 7" />
                            </svg>
                          )
                        }
                      >
                        {isSaving ? 'ì €ì¥ ì¤‘...' : 'ë©´ì ‘ ì¢…ë£Œ'}
                      </Button>

                      {/* ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ë²„íŠ¼ */}
                      <button
                        onClick={testWithMakeWebhook}
                        disabled={isSaving}
                        className="text-xs px-3 py-2 bg-amber-500/20 text-amber-400 rounded hover:bg-amber-500/30 disabled:opacity-50"
                      >
                        ğŸ§ª Make ì›¹í›… í…ŒìŠ¤íŠ¸
                      </button>
                    </>
                  ) : (
                    <Button
                      variant="primary"
                      size="lg"
                      onClick={goToResult}
                      rightIcon={
                        <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                          <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M13 7l5 5m0 0l-5 5m5-5H6" />
                        </svg>
                      }
                    >
                      ê²°ê³¼ í™•ì¸í•˜ê¸°
                    </Button>
                  )}
                </div>
              </motion.div>
            )}
          </AnimatePresence>
        </Card>

        {/* í•˜ë‹¨ ì•ˆë‚´ */}
        {(phase === 'user-ready' || phase === 'user-recording') && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            className="mt-6 text-center text-slate-500 text-sm"
          >
            ğŸ’¡ ë˜ë ·í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”. ë‹µë³€ì´ ëë‚˜ë©´ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”.
          </motion.div>
        )}
      </div>
    </div>
  );
}
